{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules import Module\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import decimal\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datafn\n",
    "def devision_data(size):\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    for i in range(int(size/BATCH_SIZE)):\n",
    "        xbatch = []\n",
    "        ybatch = []\n",
    "        for j in range(BATCH_SIZE):\n",
    "            i1, i2 = float(decimal.Decimal(random.randrange(100, 2000))/100), float(decimal.Decimal(random.randrange(100, 2000))/100)\n",
    "            y = i1 / i2 / 100\n",
    "            xbatch.append([i1, i2])\n",
    "            ybatch.append([y])\n",
    "        xbatch = torch.tensor(xbatch, dtype=torch.float)\n",
    "        ybatch = torch.tensor(ybatch)\n",
    "        xdata.append(xbatch)\n",
    "        ydata.append(ybatch)\n",
    "    return list(zip(xdata, ydata))\n",
    "\n",
    "train_data = devision_data(64000)\n",
    "test_data = devision_data(12800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom activation function\n",
    "class CustomActivation(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        x = torch.where(\n",
    "            x <= 0, 1.359140915 * (x-1).exp(), \n",
    "            torch.where(\n",
    "                x > 15, 1 - 1/(109.0858178 * x - 1403.359435), \n",
    "                0.03 * (1000000 * x + 1).log() + 0.5\n",
    "            )\n",
    "        )\n",
    "        ctx.save_for_backward(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        return grad_output * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "act_fn = CustomActivation()\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(2, 2)\n",
    "        self.l2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = act_fn.apply(x)\n",
    "        x = self.l2(x)\n",
    "        x = act_fn.apply(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod\n",
    "load = input('load? y/n ')\n",
    "if load == 'y':\n",
    "    model = torch.load('./model/Torch.pth')\n",
    "    while True:\n",
    "        inputs = input('\\ninputs: ')\n",
    "        try:\n",
    "            print(model(torch.tensor([int(inputs.split(',')[0].strip()), int(inputs.split(',')[1].strip())], dtype=torch.float)).item() * 20)\n",
    "        except:\n",
    "            exit()\n",
    "else:\n",
    "    model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 1]], which is output 0 of CustomActivationBackward, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20700/3387415852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20700/3387415852.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capgemini\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capgemini\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capgemini\\lib\\site-packages\\torch\\autograd\\function.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m# _forward_cls is defined by derived class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20700/1328095891.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(ctx, grad_output)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_output\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 1]], which is output 0 of CustomActivationBackward, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_id, (data, target) in enumerate(train_data):\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        Y_pred = model(data)\n",
    "        loss = criterion(Y_pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch + 1, batch_id * len(data), BATCH_SIZE * len(train_data),\n",
    "                    100. * batch_id / len(train_data), loss.item()))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    totalLoss = 0\n",
    "    for data, target in test_data:\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        Y_pred = model(data)\n",
    "        loss = criterion(Y_pred, target)\n",
    "        totalLoss += loss\n",
    "    print('Custom Durchschnittsloss: ', totalLoss / len(test_data))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "# 3.8294e-15\n",
    "# print(model.l1.weight, model.l1.bias, model.l1.weight.shape, model.l1.bias.shape)\n",
    "# print(model.l2.weight, model.l2.bias, model.l2.weight.shape, model.l2.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Durchschnittsloss:  tensor(3.8259e-15, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "l1HardWeights = torch.tensor([[0.000001, 0.0], [0.0, 0.000001]])\n",
    "l2HardWeights = torch.tensor([[33.3333, -33.3333]])\n",
    "l1HardBias = torch.tensor([-0.000001, -0.000001])\n",
    "l2HardBias = torch.tensor([-3.912023])\n",
    "model.l1.weight = torch.nn.Parameter(l1HardWeights)\n",
    "model.l2.weight = torch.nn.Parameter(l2HardWeights)\n",
    "model.l1.bias = torch.nn.Parameter(l1HardBias)\n",
    "model.l2.bias = torch.nn.Parameter(l2HardBias)\n",
    "# print(model.l1.weight, model.l1.bias, model.l1.weight.shape, model.l1.bias.shape)\n",
    "# print(model.l2.weight, model.l2.bias, model.l2.weight.shape, model.l2.bias.shape)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "save = input('save? y/n ')\n",
    "if save == 'y':\n",
    "    model_folder_path = './model'\n",
    "    file_name='Torch.pth'\n",
    "    if not os.path.exists(model_folder_path):\n",
    "        os.makedirs(model_folder_path)\n",
    "\n",
    "    file_name = os.path.join(model_folder_path, file_name)\n",
    "    torch.save(model, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/64000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [128/64000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [256/64000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [384/64000 (1%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [512/64000 (1%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [640/64000 (1%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [768/64000 (1%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [896/64000 (1%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [1024/64000 (2%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [1152/64000 (2%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [1280/64000 (2%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [1408/64000 (2%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [1536/64000 (2%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [1664/64000 (3%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [1792/64000 (3%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [1920/64000 (3%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [2048/64000 (3%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [2176/64000 (3%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [2304/64000 (4%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [2432/64000 (4%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [2560/64000 (4%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [2688/64000 (4%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [2816/64000 (4%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [2944/64000 (5%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3072/64000 (5%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3200/64000 (5%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3328/64000 (5%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3456/64000 (5%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3584/64000 (6%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3712/64000 (6%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3840/64000 (6%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3968/64000 (6%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4096/64000 (6%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4224/64000 (7%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4352/64000 (7%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4480/64000 (7%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4608/64000 (7%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4736/64000 (7%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4864/64000 (8%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4992/64000 (8%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [5120/64000 (8%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [5248/64000 (8%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [5376/64000 (8%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [5504/64000 (9%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [5632/64000 (9%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [5760/64000 (9%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [5888/64000 (9%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6016/64000 (9%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6144/64000 (10%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6272/64000 (10%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6400/64000 (10%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6528/64000 (10%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6656/64000 (10%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6784/64000 (11%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6912/64000 (11%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7040/64000 (11%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7168/64000 (11%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7296/64000 (11%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7424/64000 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7552/64000 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7680/64000 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7808/64000 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7936/64000 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [8064/64000 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [8192/64000 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [8320/64000 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [8448/64000 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [8576/64000 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [8704/64000 (14%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [8832/64000 (14%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [8960/64000 (14%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9088/64000 (14%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9216/64000 (14%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9344/64000 (15%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9472/64000 (15%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9600/64000 (15%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9728/64000 (15%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9856/64000 (15%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9984/64000 (16%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [10112/64000 (16%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [10240/64000 (16%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [10368/64000 (16%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [10496/64000 (16%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [10624/64000 (17%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [10752/64000 (17%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [10880/64000 (17%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11008/64000 (17%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11136/64000 (17%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11264/64000 (18%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11392/64000 (18%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11520/64000 (18%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11648/64000 (18%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11776/64000 (18%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11904/64000 (19%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12032/64000 (19%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12160/64000 (19%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12288/64000 (19%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12416/64000 (19%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12544/64000 (20%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12672/64000 (20%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12800/64000 (20%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12928/64000 (20%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [13056/64000 (20%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [13184/64000 (21%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [13312/64000 (21%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [13440/64000 (21%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [13568/64000 (21%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [13696/64000 (21%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [13824/64000 (22%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [13952/64000 (22%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [14080/64000 (22%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [14208/64000 (22%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [14336/64000 (22%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [14464/64000 (23%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [14592/64000 (23%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [14720/64000 (23%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [14848/64000 (23%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [14976/64000 (23%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [15104/64000 (24%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [15232/64000 (24%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [15360/64000 (24%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [15488/64000 (24%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [15616/64000 (24%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [15744/64000 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [15872/64000 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16000/64000 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16128/64000 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16256/64000 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16384/64000 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16512/64000 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16640/64000 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16768/64000 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16896/64000 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [17024/64000 (27%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [17152/64000 (27%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [17280/64000 (27%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [17408/64000 (27%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [17536/64000 (27%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [17664/64000 (28%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [17792/64000 (28%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [17920/64000 (28%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [18048/64000 (28%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [18176/64000 (28%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [18304/64000 (29%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [18432/64000 (29%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [18560/64000 (29%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [18688/64000 (29%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [18816/64000 (29%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [18944/64000 (30%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19072/64000 (30%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19200/64000 (30%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19328/64000 (30%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19456/64000 (30%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19584/64000 (31%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19712/64000 (31%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19840/64000 (31%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19968/64000 (31%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [20096/64000 (31%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [20224/64000 (32%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [20352/64000 (32%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [20480/64000 (32%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [20608/64000 (32%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [20736/64000 (32%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [20864/64000 (33%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [20992/64000 (33%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [21120/64000 (33%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [21248/64000 (33%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [21376/64000 (33%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [21504/64000 (34%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [21632/64000 (34%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [21760/64000 (34%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [21888/64000 (34%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [22016/64000 (34%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [22144/64000 (35%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [22272/64000 (35%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [22400/64000 (35%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [22528/64000 (35%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [22656/64000 (35%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [22784/64000 (36%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [22912/64000 (36%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [23040/64000 (36%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [23168/64000 (36%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [23296/64000 (36%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [23424/64000 (37%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [23552/64000 (37%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [23680/64000 (37%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [23808/64000 (37%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [23936/64000 (37%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [24064/64000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [24192/64000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [24320/64000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [24448/64000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [24576/64000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [24704/64000 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [24832/64000 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [24960/64000 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [25088/64000 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [25216/64000 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [25344/64000 (40%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [25472/64000 (40%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [25600/64000 (40%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [25728/64000 (40%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [25856/64000 (40%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [25984/64000 (41%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [26112/64000 (41%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [26240/64000 (41%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [26368/64000 (41%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [26496/64000 (41%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [26624/64000 (42%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [26752/64000 (42%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [26880/64000 (42%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [27008/64000 (42%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [27136/64000 (42%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [27264/64000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [27392/64000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [27520/64000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [27648/64000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [27776/64000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [27904/64000 (44%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [28032/64000 (44%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [28160/64000 (44%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [28288/64000 (44%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [28416/64000 (44%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [28544/64000 (45%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [28672/64000 (45%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [28800/64000 (45%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [28928/64000 (45%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [29056/64000 (45%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [29184/64000 (46%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [29312/64000 (46%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [29440/64000 (46%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [29568/64000 (46%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [29696/64000 (46%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [29824/64000 (47%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [29952/64000 (47%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [30080/64000 (47%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [30208/64000 (47%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [30336/64000 (47%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [30464/64000 (48%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [30592/64000 (48%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [30720/64000 (48%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [30848/64000 (48%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [30976/64000 (48%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [31104/64000 (49%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [31232/64000 (49%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [31360/64000 (49%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [31488/64000 (49%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [31616/64000 (49%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [31744/64000 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [31872/64000 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [32000/64000 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [32128/64000 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [32256/64000 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [32384/64000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [32512/64000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [32640/64000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [32768/64000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [32896/64000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [33024/64000 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [33152/64000 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [33280/64000 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [33408/64000 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [33536/64000 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [33664/64000 (53%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [33792/64000 (53%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [33920/64000 (53%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [34048/64000 (53%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [34176/64000 (53%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [34304/64000 (54%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [34432/64000 (54%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [34560/64000 (54%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [34688/64000 (54%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [34816/64000 (54%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [34944/64000 (55%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [35072/64000 (55%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [35200/64000 (55%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [35328/64000 (55%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [35456/64000 (55%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [35584/64000 (56%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [35712/64000 (56%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [35840/64000 (56%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [35968/64000 (56%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [36096/64000 (56%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [36224/64000 (57%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [36352/64000 (57%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [36480/64000 (57%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [36608/64000 (57%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [36736/64000 (57%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [36864/64000 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [36992/64000 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [37120/64000 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [37248/64000 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [37376/64000 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [37504/64000 (59%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [37632/64000 (59%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [37760/64000 (59%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [37888/64000 (59%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [38016/64000 (59%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [38144/64000 (60%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [38272/64000 (60%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [38400/64000 (60%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [38528/64000 (60%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [38656/64000 (60%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [38784/64000 (61%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [38912/64000 (61%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [39040/64000 (61%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [39168/64000 (61%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [39296/64000 (61%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [39424/64000 (62%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [39552/64000 (62%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [39680/64000 (62%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [39808/64000 (62%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [39936/64000 (62%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [40064/64000 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [40192/64000 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [40320/64000 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [40448/64000 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [40576/64000 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [40704/64000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [40832/64000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [40960/64000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [41088/64000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [41216/64000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [41344/64000 (65%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [41472/64000 (65%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [41600/64000 (65%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [41728/64000 (65%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [41856/64000 (65%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [41984/64000 (66%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [42112/64000 (66%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [42240/64000 (66%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [42368/64000 (66%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [42496/64000 (66%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [42624/64000 (67%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [42752/64000 (67%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [42880/64000 (67%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [43008/64000 (67%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [43136/64000 (67%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [43264/64000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [43392/64000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [43520/64000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [43648/64000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [43776/64000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [43904/64000 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [44032/64000 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [44160/64000 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [44288/64000 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [44416/64000 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [44544/64000 (70%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [44672/64000 (70%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [44800/64000 (70%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [44928/64000 (70%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [45056/64000 (70%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [45184/64000 (71%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [45312/64000 (71%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [45440/64000 (71%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [45568/64000 (71%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [45696/64000 (71%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [45824/64000 (72%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [45952/64000 (72%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [46080/64000 (72%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [46208/64000 (72%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [46336/64000 (72%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [46464/64000 (73%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [46592/64000 (73%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [46720/64000 (73%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [46848/64000 (73%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [46976/64000 (73%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [47104/64000 (74%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [47232/64000 (74%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [47360/64000 (74%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [47488/64000 (74%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [47616/64000 (74%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [47744/64000 (75%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [47872/64000 (75%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [48000/64000 (75%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [48128/64000 (75%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [48256/64000 (75%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [48384/64000 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [48512/64000 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [48640/64000 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [48768/64000 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [48896/64000 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [49024/64000 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [49152/64000 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [49280/64000 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [49408/64000 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [49536/64000 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [49664/64000 (78%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [49792/64000 (78%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [49920/64000 (78%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [50048/64000 (78%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [50176/64000 (78%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [50304/64000 (79%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [50432/64000 (79%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [50560/64000 (79%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [50688/64000 (79%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [50816/64000 (79%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [50944/64000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [51072/64000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [51200/64000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [51328/64000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [51456/64000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [51584/64000 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [51712/64000 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [51840/64000 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [51968/64000 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [52096/64000 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [52224/64000 (82%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [52352/64000 (82%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [52480/64000 (82%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [52608/64000 (82%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [52736/64000 (82%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [52864/64000 (83%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [52992/64000 (83%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [53120/64000 (83%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [53248/64000 (83%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [53376/64000 (83%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [53504/64000 (84%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [53632/64000 (84%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [53760/64000 (84%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [53888/64000 (84%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [54016/64000 (84%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [54144/64000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [54272/64000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [54400/64000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [54528/64000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [54656/64000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [54784/64000 (86%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [54912/64000 (86%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [55040/64000 (86%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [55168/64000 (86%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [55296/64000 (86%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [55424/64000 (87%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [55552/64000 (87%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [55680/64000 (87%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [55808/64000 (87%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [55936/64000 (87%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [56064/64000 (88%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [56192/64000 (88%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [56320/64000 (88%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [56448/64000 (88%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [56576/64000 (88%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [56704/64000 (89%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [56832/64000 (89%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [56960/64000 (89%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [57088/64000 (89%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [57216/64000 (89%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [57344/64000 (90%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [57472/64000 (90%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [57600/64000 (90%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [57728/64000 (90%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [57856/64000 (90%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [57984/64000 (91%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [58112/64000 (91%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [58240/64000 (91%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [58368/64000 (91%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [58496/64000 (91%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [58624/64000 (92%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [58752/64000 (92%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [58880/64000 (92%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [59008/64000 (92%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [59136/64000 (92%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [59264/64000 (93%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [59392/64000 (93%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [59520/64000 (93%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [59648/64000 (93%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [59776/64000 (93%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [59904/64000 (94%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [60032/64000 (94%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [60160/64000 (94%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [60288/64000 (94%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [60416/64000 (94%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [60544/64000 (95%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [60672/64000 (95%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [60800/64000 (95%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [60928/64000 (95%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [61056/64000 (95%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [61184/64000 (96%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [61312/64000 (96%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [61440/64000 (96%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [61568/64000 (96%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [61696/64000 (96%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [61824/64000 (97%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [61952/64000 (97%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [62080/64000 (97%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [62208/64000 (97%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [62336/64000 (97%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [62464/64000 (98%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [62592/64000 (98%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [62720/64000 (98%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [62848/64000 (98%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [62976/64000 (98%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [63104/64000 (99%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [63232/64000 (99%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [63360/64000 (99%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [63488/64000 (99%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [63616/64000 (99%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [63744/64000 (100%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [63872/64000 (100%)]\tLoss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "train(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b8149ac4395d9070500b42afe2f3634df0963551b295706ab1eed5a6da2e06c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('capgemini': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
